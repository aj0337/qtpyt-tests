{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from gpaw.lcao.tools import remove_pbc\n",
    "from qtpyt.basis import Basis\n",
    "from ase.io import read\n",
    "from qtpyt.block_tridiag import graph_partition, greenfunction\n",
    "from qtpyt.surface.principallayer import PrincipalSelfEnergy\n",
    "from qtpyt.surface.tools import prepare_leads_matrices\n",
    "from qtpyt.tools import remove_pbc, rotate_couplings\n",
    "from qtpyt.projector import ProjectedGreenFunction\n",
    "from qtpyt.hybridization import Hybridization\n",
    "from qtpyt.continued_fraction import get_ao_charge\n",
    "from scipy.linalg import eigvalsh\n",
    "from qtpyt.parallel import comm\n",
    "from qtpyt.parallel.egrid import GridDesc\n",
    "\n",
    "\n",
    "from ase.io import read\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../output/compute_run'\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "\n",
    "H_subdiagonalized, S_subdiagonalized = np.load(f\"{data_folder}/hs_los_lowdin.npy\")\n",
    "H_subdiagonalized = H_subdiagonalized.astype(np.complex128)\n",
    "S_subdiagonalized = S_subdiagonalized.astype(np.complex128)\n",
    "\n",
    "GPWDEVICEDIR = '../dft/device/'\n",
    "GPWLEADSDIR = '../dft/leads/'\n",
    "\n",
    "cc_path = Path(GPWDEVICEDIR)\n",
    "pl_path = Path(GPWLEADSDIR)\n",
    "\n",
    "H_leads_lcao, S_leads_lcao = np.load(pl_path / 'hs_pl_k.npy')\n",
    "\n",
    "basis_dict = {'Au': 9, 'H': 5, 'C': 13, 'N': 13}\n",
    "\n",
    "leads_atoms = read(pl_path / 'leads.xyz')\n",
    "leads_basis = Basis.from_dictionary(leads_atoms, basis_dict)\n",
    "\n",
    "device_atoms = read(cc_path / 'scatt.xyz')\n",
    "device_basis = Basis.from_dictionary(device_atoms, basis_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [0,810,1116,1278,1584,2394]\n",
    "\n",
    "# Define energy range and broadening factor for the Green's function calculation\n",
    "de = 0.2\n",
    "energies = np.arange(-3., 3. + de / 2., de).round(7)\n",
    "eta = 1e-3\n",
    "\n",
    "# Define the number of repetitions (Nr) and unit cell repetition in the leads\n",
    "Nr = (1, 5, 3)\n",
    "unit_cell_rep_in_leads = (5, 5, 3)\n",
    "\n",
    "# Define parameters for matsubara grid\n",
    "ne = 30\n",
    "beta = 70.\n",
    "matsubara_energies = 1.j * (2 * np.arange(ne) + 1) * np.pi / beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the k-points and matrices for the leads (Hamiltonian and overlap matrices)\n",
    "kpts_t, h_leads_kii, s_leads_kii, h_leads_kij, s_leads_kij = prepare_leads_matrices(\n",
    "    H_leads_lcao, S_leads_lcao, unit_cell_rep_in_leads, align=(0, H_subdiagonalized[0, 0, 0]))\n",
    "\n",
    "# Remove periodic boundary conditions (PBC) from the device Hamiltonian and overlap matrices\n",
    "remove_pbc(device_basis, H_subdiagonalized)\n",
    "remove_pbc(device_basis, S_subdiagonalized)\n",
    "\n",
    "# Initialize self-energy list for left and right leads\n",
    "self_energy = [None, None, None]\n",
    "self_energy[0] = PrincipalSelfEnergy(kpts_t, (h_leads_kii, s_leads_kii), (h_leads_kij, s_leads_kij), Nr=Nr)\n",
    "self_energy[1] = PrincipalSelfEnergy(kpts_t, (h_leads_kii, s_leads_kii), (h_leads_kij, s_leads_kij), Nr=Nr, id='right')\n",
    "\n",
    "# Rotate the couplings for the leads based on the specified basis and repetition Nr\n",
    "rotate_couplings(leads_basis, self_energy[0], Nr)\n",
    "rotate_couplings(leads_basis, self_energy[1], Nr)\n",
    "\n",
    "# Tridiagonalize the device Hamiltonian and overlap matrices based on the partitioned nodes\n",
    "hs_list_ii, hs_list_ij = graph_partition.tridiagonalize(nodes, H_subdiagonalized[0], S_subdiagonalized[0])\n",
    "del H_subdiagonalized, S_subdiagonalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Green's function solver with the tridiagonalized matrices and self-energies\n",
    "gf = greenfunction.GreenFunction(hs_list_ii,\n",
    "                                hs_list_ij,\n",
    "                                [(0, self_energy[0]),\n",
    "                                (len(hs_list_ii) - 1, self_energy[1])],\n",
    "                                solver='dyson',\n",
    "                                eta=eta)\n",
    "\n",
    "\n",
    "# Define active region and the Green's function for the active region\n",
    "\n",
    "index_active_region = np.load(f\"{data_folder}/index_active_region.npy\")\n",
    "\n",
    "gfp = ProjectedGreenFunction(gf, index_active_region)\n",
    "hyb = Hybridization(gfp)\n",
    "\n",
    "\n",
    "n_A = len(index_active_region)\n",
    "gd = GridDesc(energies, n_A, complex)\n",
    "HB = gd.empty_aligned_orbs()\n",
    "\n",
    "for e, energy in enumerate(gd.energies):\n",
    "    HB[e] = hyb.retarded(energy)\n",
    "\n",
    "filename = os.path.join(data_folder, 'hybridization.bin')\n",
    "gd.write(HB,filename)\n",
    "del HB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matsubara\n",
    "gf.eta = 0.\n",
    "assert self_energy[0].eta == 0.\n",
    "assert self_energy[1].eta == 0.\n",
    "\n",
    "mat_gd = GridDesc(matsubara_energies, n_A, complex)\n",
    "HB_mat = mat_gd.empty_aligned_orbs()\n",
    "\n",
    "for e, energy in enumerate(mat_gd.energies):\n",
    "    HB_mat[e] = hyb.retarded(energy)\n",
    "\n",
    "# Save the Matsubara hybrid data\n",
    "filename = os.path.join(data_folder, 'matsubara_hybridization.bin')\n",
    "mat_gd.write(HB_mat, filename)\n",
    "del HB_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if comm.rank == 0:\n",
    "    np.save(os.path.join(data_folder, 'energies.npy'), energies + 1.j * eta)\n",
    "    # Effective Hamiltonian\n",
    "    np.save(os.path.join(data_folder, 'hamiltonian.npy'), hyb.H)\n",
    "    np.save(os.path.join(data_folder, 'occupancies.npy'), get_ao_charge(gfp))\n",
    "    np.save(os.path.join(data_folder, 'matsubara_energies.npy'), matsubara_energies)\n",
    "    np.save(os.path.join(data_folder, 'hs_list_ii.npy'), hs_list_ii)\n",
    "    np.save(os.path.join(data_folder, 'hs_list_ij.npy'), hs_list_ij)\n",
    "    np.save(os.path.join(data_folder, 'self_energy.npy'), self_energy)\n",
    "    Heff = (hyb.H + hyb.retarded(0.)).real\n",
    "    np.save(os.path.join(data_folder, 'effective_hamiltonian.npy'), Heff)\n",
    "    np.save(os.path.join(data_folder, 'eigvals_Heff.npy'), eigvalsh(Heff, gfp.S))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
